{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Pigeon Proof of Concept\n",
    "\n",
    "### Overview\n",
    "With this notebook, I aim to show that news can be collected and summarized by an\n",
    "LLM using retreival augmented generation.\n",
    "\n",
    "To use it, you will need to have Ollama downloaded: https://ollama.ai/\n",
    "\n",
    "Ollama makes running an LLM locally possible without crashing your device.  For \n",
    "context, I built and tested this notebook on a Macbook Air 2020 with 8gb sillicone\n",
    "chip.\n",
    "\n",
    "I am using an untuned Mistral 7b as my LLM.  I do need to experiment with other\n",
    "LLMs, but I wanted to start with a 7b, and, from what twitter says, Mistral's\n",
    "is the best.\n",
    "\n",
    "### Details\n",
    "The notebook can be split into the following sections:\n",
    "\n",
    "0) Downloads, library imports, and feed selection\n",
    "\n",
    "1) Scraping rss feeds specfied in section 0\n",
    "\n",
    "2) Embedding content from scrape and setting up parts of chain\n",
    "\n",
    "3) Create prompt and initialize chain\n",
    "\n",
    "4) Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloads, library imports, and feed selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain bs4 sentence_transformers feedparser newspaper3k --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "import feedparser\n",
    "from requests.exceptions import Timeout\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from newspaper import Article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeds = [\n",
    "    [\"CNN Top Stories\", \"http://rss.cnn.com/rss/cnn_topstories.rss\"],\n",
    "    [\"CNN World\", \"http://rss.cnn.com/rss/cnn_world.rss\"],\n",
    "    [\"CNN US\", \"http://rss.cnn.com/rss/cnn_us.rss\"],\n",
    "    [\"CNN Business\", \"http://rss.cnn.com/rss/money_latest.rss\"],\n",
    "    [\"CNN Politics\", \"http://rss.cnn.com/rss/cnn_allpolitics.rss\"],\n",
    "    [\"CNN Tech\", \"http://rss.cnn.com/rss/cnn_tech.rss\"],\n",
    "    [\"CNN Health\", \"http://rss.cnn.com/rss/cnn_health.rss\"],\n",
    "    [\"CNN Entertainment\", \"http://rss.cnn.com/rss/cnn_showbiz.rss\"],\n",
    "    [\"CNN Travel\", \"http://rss.cnn.com/rss/cnn_travel.rss\"],\n",
    "   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping RSS Feeds\n",
    "Uses mostly the feedparser library.  We mostly just want the links to later run\n",
    "them through Newspaper3k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "\n",
    "for sub_feed in feeds:\n",
    "    feed = feedparser.parse(sub_feed[1])\n",
    "    one_day_ago = datetime.now() - timedelta(days=1)\n",
    "\n",
    "    recent_items = []\n",
    "    for entry in feed.entries:\n",
    "        try:\n",
    "            published = datetime(*entry.published_parsed[:6])\n",
    "            # if published > one_day_ago:\n",
    "            recent_items.append(entry)\n",
    "        except:\n",
    "            if not entry.title == \"\":\n",
    "                recent_items.append(entry)\n",
    "\n",
    "    for item in recent_items:\n",
    "        try:\n",
    "            links.append(item.links[0].href)\n",
    "\n",
    "        except Timeout:\n",
    "            print(\"ARTICLE COLLECTION TIMED OUT:\", item.links[0].href)\n",
    "        except Exception as e:\n",
    "            print(\"ARTICLE COLLECTION ERROR:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding content from RSS feeds\n",
    "\n",
    "We start to use langchain heavily from here on out.  Depending on the amount of text scraped from RSS feeds, \n",
    "this cell might take some time.  Generally, each link in the feed takes around 45 seconds to embed.  There are usually around 30 links per feed.\n",
    "\n",
    "First, we use Newspaper3k to get the text from the link.\n",
    "\n",
    "Next, we use \"RecursiveCharacterTextSplitter\" to split the text into semantially\n",
    "significant text.\n",
    "\n",
    "Then, we put in the context to each chunk, which helps the model cite sources.\n",
    "\n",
    "Finally, we vectorize all the documents and set up other parts of the langchain\n",
    "chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/reviews/best-bidets?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/home/editors-favorite-sustainable-products?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/gifts/best-mothers-day-gifts-2023?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/fashion/mens-spring-fashion-style-guide?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/travel/amazon-travel-products?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/money/high-yield-savings-accounts?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/money/how-to-file-taxes?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/home/how-to-compost-at-home?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/reviews/mmmat-silicone-mats?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/deals/dyson-supersonic-sale-2023-04-17?iid=CNNUnderscoredHPcontainer?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/deals/wayfair-way-day-2023-04-17?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/cnn-underscored/deals/best-amazon-deals-2023-04-12?iid=CNNUnderscoredHPcontainer\n",
      "ERROR DOWNLOADING ARTICLE: https://www.lendingtree.com/?splitterid=home-equity&cproduct=he&cchannel=content&csource=cnn&cmethod=heform&ccreative=risingequitycash_housemoneystack&placement_name=sectionfronts&ad_headline=risingequitycash&ad_image_name=housemoneystack&ctype=sectionfronts&bdst=revshare&mtaid=AC53E&esourceid=6348616\n",
      "ERROR DOWNLOADING ARTICLE: https://www.lendingtree.com/?splitterid=home-equity&cproduct=he&cchannel=content&csource=cnn&cmethod=heform&ccreative=dreambighomeequity_housemoneystack&placement_name=sectionfronts&ad_headline=dreambighomeequity&ad_image_name=housemoneystack&ctype=sectionfronts&bdst=revshare&mtaid=AC53E&esourceid=6348616\n",
      "ERROR DOWNLOADING ARTICLE: https://www.lendingtree.com/?splitterid=home-equity&cproduct=he&cchannel=content&csource=cnn&cmethod=heform&ccreative=cashoutoptions_housemoneystack&placement_name=sectionfronts&ad_headline=cashoutoptions&ad_image_name=housemoneystack&ctype=sectionfronts&bdst=revshare&mtaid=AC53E&esourceid=6348616\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/video/playlists/this-week-in-politics/\n",
      "ERROR DOWNLOADING ARTICLE: https://www.lendingtree.com/?splitterid=home-equity&cproduct=he&cchannel=content&csource=cnn&cmethod=heform&ccreative=risingequitycash_housemoneystack&placement_name=sectionfronts&ad_headline=risingequitycash&ad_image_name=housemoneystack&ctype=sectionfronts&bdst=revshare&mtaid=AC53E&esourceid=6348616\n",
      "ERROR DOWNLOADING ARTICLE: https://www.lendingtree.com/?splitterid=home-equity&cproduct=he&cchannel=content&csource=cnn&cmethod=heform&ccreative=dreambighomeequity_housemoneystack&placement_name=sectionfronts&ad_headline=dreambighomeequity&ad_image_name=housemoneystack&ctype=sectionfronts&bdst=revshare&mtaid=AC53E&esourceid=6348616\n",
      "ERROR DOWNLOADING ARTICLE: https://www.lendingtree.com/?splitterid=home-equity&cproduct=he&cchannel=content&csource=cnn&cmethod=heform&ccreative=cashoutoptions_housemoneystack&placement_name=sectionfronts&ad_headline=cashoutoptions&ad_image_name=housemoneystack&ctype=sectionfronts&bdst=revshare&mtaid=AC53E&esourceid=6348616\n",
      "ERROR DOWNLOADING ARTICLE: https://www.comparecards.com/?splitterid=coca-category-low-interest&mtaid=8631C&esourceid=6497536&utm_source=cnn&tar=sectionfronts&grp=cat-low-interest&utm_content=use+the+right+card+for+holiday+gifts+you+could+save+hundreds&adt=brunetteredcard&placement_name=sectionfronts&ad_headline=use+the+right+card+for+holiday+gifts+you+could+save+hundreds&ad_image_name=brunetteredcard&utm_medium=native&ad_position=0&bdst=revshare\n",
      "ERROR DOWNLOADING ARTICLE: https://www.comparecards.com/?splitterid=coca-category-low-interest&mtaid=8631C&esourceid=6497536&utm_source=cnn&tar=sectionfronts&grp=cat-low-interest&utm_content=10+cards+charging+0+interest+until+2024&adt=brunetteredcard&placement_name=sectionfronts&ad_headline=10+cards+charging+0+interest+until+2024&ad_image_name=brunetteredcard&utm_medium=native&ad_position=0&bdst=revshare\n",
      "ERROR DOWNLOADING ARTICLE: https://www.comparecards.com/?splitterid=coca-cat-cash-back&mtaid=8631C&esourceid=6488886&utm_source=cnn&tar=sectionfronts&grp=cat-cb&utm_content=get+a+200+cash+back+bonus+on+holiday+gift+buying&adt=brunetteredcard&placement_name=sectionfronts&ad_headline=get+a+200+cash+back+bonus+on+holiday+gift+buying&ad_image_name=brunetteredcard&utm_medium=native&ad_position=0&bdst=revshare\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/2020/08/28/cnn-underscored/theragun-review/index.html\n",
      "ERROR DOWNLOADING ARTICLE: https://www.cnn.com/2021/01/13/cnn-underscored/best-workout-clothes-for-women/index.html\n"
     ]
    }
   ],
   "source": [
    "# Using Ollama to host mistral 7b, which, from what I read\n",
    "# best model that I can run locally\n",
    "model = Ollama(model='mistral')\n",
    "\n",
    "# I chose this embedder because it is small and well performing according to \n",
    "# HF's MTEB leaderboard: https://huggingface.co/spaces/mteb/leaderboard\n",
    "embedder_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "embedder = HuggingFaceBgeEmbeddings(\n",
    "    model_name=embedder_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# Recursive text splitter splits text into semantically meaningful chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "# This is where we will store the different chunks of text\n",
    "split_data = []\n",
    "\n",
    "for link in links:\n",
    "    good_2_go = True\n",
    "    try:\n",
    "        # Using newspaper3k to download and parse the article\n",
    "        article = Article(link)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "    except:\n",
    "        # There are certain articles that newspaper3k can't parse\n",
    "        # I catch those here and see if they are of any value (They usually aren't)\n",
    "        good_2_go = False\n",
    "        print(\"ERROR DOWNLOADING ARTICLE:\", link)\n",
    "    \n",
    "    # This metadata will be added to the beginning of each chunk\n",
    "    # Doing this decreases hallucinations in citations\n",
    "    meta_data = f\"Source \\n Title: {article.title} \\n Url: {link} \\\n",
    "        n Publish Date: {article.publish_date} \\n  Excerpt from source: \"\n",
    "\n",
    "    if good_2_go and not article.text is None:\n",
    "        # Splitting\n",
    "        candidate = text_splitter.create_documents([article.text])\n",
    "\n",
    "        temp_split_data = text_splitter.split_documents(candidate)\n",
    "\n",
    "        # Adding metadata to each chunk\n",
    "        for split in temp_split_data:\n",
    "            split.page_content = meta_data + split.page_content\n",
    "        \n",
    "        split_data += temp_split_data\n",
    "\n",
    "# vectorstore is the vector database using lightweight Chromadb\n",
    "vectorstore = Chroma.from_documents(documents=split_data, embedding=embedder)\n",
    "\n",
    "# Yet another part of langchain's abstractions\n",
    "# Used to parse the output of the model\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Lets us query the db to fill out the prompt template below\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": vectorstore.as_retriever(), \"question\": RunnablePassthrough()}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template and initializing chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt engineering is a constant process, especially with a smaller model\n",
    "template = \"\"\"\n",
    "You are a news expert who answers questions about news.  \n",
    "\n",
    "You must only use the most recent data from this context:\n",
    "{context}\n",
    "\n",
    "Do not rely on your historical records.\n",
    "\n",
    "Answer as concisely as possible, but make sure that your information\n",
    "lines up with the sources.  \n",
    "\n",
    "Your answer should be in the following format:\n",
    "    Your answer to the question here.\n",
    "\n",
    "    Sources: [article title, source link, publish date]\n",
    "\n",
    "Cite all Possible sources and put each on a new line.\n",
    "If you don't have the relevent information to answer the question or a source,\n",
    "tell the user so.  Err on the side of caution.\n",
    "\n",
    "If the question or topic is off topic and not about news at all, tell the user so.\n",
    "\n",
    "Here is the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# The final runnable in the chain\n",
    "chain = setup_and_retrieval | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up and running!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT FETCHED:\n",
      "{'context': [Document(page_content='Source \\n Title: EU asks Meta for more details on efforts to stop Israel-Hamas war misinformation \\n Url: https://www.cnn.com/2023/10/19/tech/eu-meta-tiktok-israel-content-disinformation/index.html         n Publish Date: 2023-10-19 00:00:00 \\n  Excerpt from source: London CNN —\\n\\nThe European Union has told Meta it has a week to explain in greater detail how it is fighting the spread of illegal content and disinformation on its Facebook and Instagram platforms following the attacks across Israel by Hamas.\\n\\nThe European Commission, the bloc’s executive arm, said it had sent the formal request for information to Meta (META) Thursday.'), Document(page_content='Source \\n Title: EU asks Meta for more details on efforts to stop Israel-Hamas war misinformation \\n Url: https://www.cnn.com/2023/10/19/tech/eu-meta-tiktok-israel-content-disinformation/index.html         n Publish Date: 2023-10-19 00:00:00 \\n  Excerpt from source: London CNN —\\n\\nThe European Union has told Meta it has a week to explain in greater detail how it is fighting the spread of illegal content and disinformation on its Facebook and Instagram platforms following the attacks across Israel by Hamas.\\n\\nThe European Commission, the bloc’s executive arm, said it had sent the formal request for information to Meta (META) Thursday.'), Document(page_content='Source \\n Title: EU asks Meta for more details on efforts to stop Israel-Hamas war misinformation \\n Url: https://www.cnn.com/2023/10/19/tech/eu-meta-tiktok-israel-content-disinformation/index.html         n Publish Date: 2023-10-19 00:00:00 \\n  Excerpt from source: On Friday, Meta said its teams had been working “around the clock” since the attacks by Hamas on October 7 to monitor its platforms and outlined some of its actions against misinformation and content that violates its policies and standards.'), Document(page_content='Source \\n Title: EU asks Meta for more details on efforts to stop Israel-Hamas war misinformation \\n Url: https://www.cnn.com/2023/10/19/tech/eu-meta-tiktok-israel-content-disinformation/index.html         n Publish Date: 2023-10-19 00:00:00 \\n  Excerpt from source: On Friday, Meta said its teams had been working “around the clock” since the attacks by Hamas on October 7 to monitor its platforms and outlined some of its actions against misinformation and content that violates its policies and standards.')], 'question': 'What is the most recent news in Isreal?'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(\"---------------\")\\n\\nprint(\"\\nANSWER:\")\\nprint(chain.invoke(question))'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "question = \"What is the most recent news in Isreal?\"\n",
    "\n",
    "# I want to see what context the model is using to answer the question\n",
    "print(\"CONTEXT FETCHED:\")\n",
    "print(setup_and_retrieval.invoke(question))\n",
    "\n",
    "\"\"\"print(\"---------------\")\n",
    "\n",
    "print(\"\\nANSWER:\")\n",
    "print(chain.invoke(question))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "This notebook is more of a proof of concept that we can use LLMs to parse through news.  It's not meant to be perfect and it certainly isn't.\n",
    "\n",
    "The design could be improved in the following ways (no particular order):\n",
    "\n",
    " - Improving from a 7b model.  Probably the biggest barrier is that a 7b model's outputs can only be so good.  It often doesn't follow instuctions or just avoids outputting sometimes.  Perhaps this behavior would change with a better model, though I'm skeptical that I'd be able to run any larger model on my M1 8GB.\n",
    " - Fine tuning on custom dataset.  Might be possible on slightly better computer using some kind of PEFT technique.  I'd have to use gpt to get me some traning data, though.\n",
    " - Improve news collection pipeline.  It's important to get a variety of sources, and maybe the best way to do that is not just through arbirary RSS feeds.\n",
    " - LLM memory.  The ability to ask follow up questions would be nice, but I doubt this model's ability to handle very specific questions.\n",
    "  - Better prompt engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
