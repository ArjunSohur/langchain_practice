{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Pigeon Proof of Concept\n",
    "\n",
    "### Overview\n",
    "With this notebook, I aim to show that news can be collected and summarized by an\n",
    "LLM using retreival augmented generation.\n",
    "\n",
    "To use it, you will need to have Ollama downloaded: https://ollama.ai/\n",
    "\n",
    "Ollama makes running an LLM locally possible without crashing your device.  For \n",
    "context, I built and tested this notebook on a Macbook Air 2020 with 8gb sillicone\n",
    "chip.\n",
    "\n",
    "I am using an untuned Mistral 7b as my LLM.  I do need to experiment with other\n",
    "LLMs, but I wanted to start with a 7b, and, from what twitter says, Mistral's\n",
    "is the best.\n",
    "\n",
    "### Details\n",
    "The notebook can be split into the following sections:\n",
    "\n",
    "0) Downloads, library imports, and feed selection\n",
    "\n",
    "1) Scraping rss feeds specfied in section 0\n",
    "\n",
    "2) Embedding content from scrape and setting up parts of chain\n",
    "\n",
    "3) Create prompt and initialize chain\n",
    "\n",
    "4) Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloads, library imports, and feed selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain bs4 sentence_transformers feedparser newspaper3k --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "import feedparser\n",
    "from requests.exceptions import Timeout\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from newspaper import Article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeds = [\n",
    "    [\"CNN Top Stories\", \"http://rss.cnn.com/rss/cnn_topstories.rss\"],\n",
    "    [\"CNN World\", \"http://rss.cnn.com/rss/cnn_world.rss\"],\n",
    "    [\"CNN US\", \"http://rss.cnn.com/rss/cnn_us.rss\"],\n",
    "    [\"CNN Business\", \"http://rss.cnn.com/rss/money_latest.rss\"],\n",
    "    [\"CNN Politics\", \"http://rss.cnn.com/rss/cnn_allpolitics.rss\"],\n",
    "    [\"CNN Tech\", \"http://rss.cnn.com/rss/cnn_tech.rss\"],\n",
    "    [\"CNN Health\", \"http://rss.cnn.com/rss/cnn_health.rss\"],\n",
    "    [\"CNN Entertainment\", \"http://rss.cnn.com/rss/cnn_showbiz.rss\"],\n",
    "    [\"CNN Travel\", \"http://rss.cnn.com/rss/cnn_travel.rss\"],\n",
    "   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping RSS Feeds\n",
    "Uses mostly the feedparser library.  We mostly just want the links to later run\n",
    "them through Newspaper3k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "29\n",
      "29\n",
      "1\n",
      "30\n",
      "20\n",
      "29\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "\n",
    "for sub_feed in feeds:\n",
    "    feed = feedparser.parse(sub_feed[1])\n",
    "    one_day_ago = datetime.now() - timedelta(days=1)\n",
    "\n",
    "    print(len(feed.entries))\n",
    "\n",
    "    recent_items = []\n",
    "    for entry in feed.entries:\n",
    "        try:\n",
    "            published = datetime(*entry.published_parsed[:6])\n",
    "            # if published > one_day_ago:\n",
    "            recent_items.append(entry)\n",
    "        except:\n",
    "            if not entry.title == \"\":\n",
    "                recent_items.append(entry)\n",
    "\n",
    "    for item in recent_items:\n",
    "        try:\n",
    "            links.append(item.links[0].href)\n",
    "\n",
    "        except Timeout:\n",
    "            print(\"ARTICLE COLLECTION TIMED OUT:\", item.links[0].href)\n",
    "        except Exception as e:\n",
    "            print(\"ARTICLE COLLECTION ERROR:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding content from RSS feeds\n",
    "\n",
    "We start to use langchain heavily from here on out.  Depending on the amount of text scraped from RSS feeds, \n",
    "this cell might take some time.  Generally, each link in the feed takes around 45 seconds to embed.  There are usually around 30 links per feed.\n",
    "\n",
    "First, we use Newspaper3k to get the text from the link.\n",
    "\n",
    "Next, we use \"RecursiveCharacterTextSplitter\" to split the text into semantially\n",
    "significant text.\n",
    "\n",
    "Then, we put in the context to each chunk, which helps the model cite sources.\n",
    "\n",
    "Finally, we vectorize all the documents and set up other parts of the langchain\n",
    "chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected IDs to be a non-empty list, got []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/arjunsohur/Desktop/langchain_tests/lc_2.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arjunsohur/Desktop/langchain_tests/lc_2.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         split_data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m temp_split_data\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arjunsohur/Desktop/langchain_tests/lc_2.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# vectorstore is the vector database using lightweight Chromadb\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arjunsohur/Desktop/langchain_tests/lc_2.ipynb#W5sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m vectorstore \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_documents(documents\u001b[39m=\u001b[39;49msplit_data, embedding\u001b[39m=\u001b[39;49membedder)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arjunsohur/Desktop/langchain_tests/lc_2.ipynb#W5sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# Yet another part of langchain's abstractions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arjunsohur/Desktop/langchain_tests/lc_2.ipynb#W5sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Used to parse the output of the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arjunsohur/Desktop/langchain_tests/lc_2.ipynb#W5sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m output_parser \u001b[39m=\u001b[39m StrOutputParser()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:771\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    770\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 771\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[1;32m    772\u001b[0m     texts\u001b[39m=\u001b[39;49mtexts,\n\u001b[1;32m    773\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    774\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[1;32m    775\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    776\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    777\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    778\u001b[0m     client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[1;32m    779\u001b[0m     client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    780\u001b[0m     collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[1;32m    781\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    782\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:729\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatch_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m create_batches\n\u001b[1;32m    723\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m create_batches(\n\u001b[1;32m    724\u001b[0m         api\u001b[39m=\u001b[39mchroma_collection\u001b[39m.\u001b[39m_client,\n\u001b[1;32m    725\u001b[0m         ids\u001b[39m=\u001b[39mids,\n\u001b[1;32m    726\u001b[0m         metadatas\u001b[39m=\u001b[39mmetadatas,\n\u001b[1;32m    727\u001b[0m         documents\u001b[39m=\u001b[39mtexts,\n\u001b[1;32m    728\u001b[0m     ):\n\u001b[0;32m--> 729\u001b[0m         chroma_collection\u001b[39m.\u001b[39;49madd_texts(\n\u001b[1;32m    730\u001b[0m             texts\u001b[39m=\u001b[39;49mbatch[\u001b[39m3\u001b[39;49m] \u001b[39mif\u001b[39;49;00m batch[\u001b[39m3\u001b[39;49m] \u001b[39melse\u001b[39;49;00m [],\n\u001b[1;32m    731\u001b[0m             metadatas\u001b[39m=\u001b[39;49mbatch[\u001b[39m2\u001b[39;49m] \u001b[39mif\u001b[39;49;00m batch[\u001b[39m2\u001b[39;49m] \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    732\u001b[0m             ids\u001b[39m=\u001b[39;49mbatch[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    733\u001b[0m         )\n\u001b[1;32m    734\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     chroma_collection\u001b[39m.\u001b[39madd_texts(texts\u001b[39m=\u001b[39mtexts, metadatas\u001b[39m=\u001b[39mmetadatas, ids\u001b[39m=\u001b[39mids)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:324\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collection\u001b[39m.\u001b[39mupsert(\n\u001b[1;32m    319\u001b[0m             embeddings\u001b[39m=\u001b[39membeddings_without_metadatas,\n\u001b[1;32m    320\u001b[0m             documents\u001b[39m=\u001b[39mtexts_without_metadatas,\n\u001b[1;32m    321\u001b[0m             ids\u001b[39m=\u001b[39mids_without_metadatas,\n\u001b[1;32m    322\u001b[0m         )\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 324\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collection\u001b[39m.\u001b[39;49mupsert(\n\u001b[1;32m    325\u001b[0m         embeddings\u001b[39m=\u001b[39;49membeddings,\n\u001b[1;32m    326\u001b[0m         documents\u001b[39m=\u001b[39;49mtexts,\n\u001b[1;32m    327\u001b[0m         ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m \u001b[39mreturn\u001b[39;00m ids\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/chromadb/api/models/Collection.py:449\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupsert\u001b[39m(\n\u001b[1;32m    422\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    423\u001b[0m     ids: OneOrMany[ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m     uris: Optional[OneOrMany[URI]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    429\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \n\u001b[1;32m    432\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m        None\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m     (\n\u001b[1;32m    443\u001b[0m         ids,\n\u001b[1;32m    444\u001b[0m         embeddings,\n\u001b[1;32m    445\u001b[0m         metadatas,\n\u001b[1;32m    446\u001b[0m         documents,\n\u001b[1;32m    447\u001b[0m         images,\n\u001b[1;32m    448\u001b[0m         uris,\n\u001b[0;32m--> 449\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_embedding_set(\n\u001b[1;32m    450\u001b[0m         ids, embeddings, metadatas, documents, images, uris\n\u001b[1;32m    451\u001b[0m     )\n\u001b[1;32m    453\u001b[0m     \u001b[39mif\u001b[39;00m embeddings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         \u001b[39mif\u001b[39;00m documents \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/chromadb/api/models/Collection.py:512\u001b[0m, in \u001b[0;36mCollection._validate_embedding_set\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris, require_embeddings_or_data)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_embedding_set\u001b[39m(\n\u001b[1;32m    496\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    497\u001b[0m     ids: OneOrMany[ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m     Optional[URIs],\n\u001b[1;32m    511\u001b[0m ]:\n\u001b[0;32m--> 512\u001b[0m     valid_ids \u001b[39m=\u001b[39m validate_ids(maybe_cast_one_to_many_ids(ids))\n\u001b[1;32m    513\u001b[0m     valid_embeddings \u001b[39m=\u001b[39m (\n\u001b[1;32m    514\u001b[0m         validate_embeddings(maybe_cast_one_to_many_embedding(embeddings))\n\u001b[1;32m    515\u001b[0m         \u001b[39mif\u001b[39;00m embeddings \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    516\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    518\u001b[0m     valid_metadatas \u001b[39m=\u001b[39m (\n\u001b[1;32m    519\u001b[0m         validate_metadatas(maybe_cast_one_to_many_metadata(metadatas))\n\u001b[1;32m    520\u001b[0m         \u001b[39mif\u001b[39;00m metadatas \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    521\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    522\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/chromadb/api/types.py:228\u001b[0m, in \u001b[0;36mvalidate_ids\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected IDs to be a list, got \u001b[39m\u001b[39m{\u001b[39;00mids\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ids) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 228\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected IDs to be a non-empty list, got \u001b[39m\u001b[39m{\u001b[39;00mids\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    229\u001b[0m seen \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    230\u001b[0m dups \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected IDs to be a non-empty list, got []"
     ]
    }
   ],
   "source": [
    "# Using Ollama to host mistral 7b, which, from what I read\n",
    "# best model that I can run locally\n",
    "model = Ollama(model='mistral')\n",
    "\n",
    "# I chose this embedder because it is small and well performing according to \n",
    "# HF's MTEB leaderboard: https://huggingface.co/spaces/mteb/leaderboard\n",
    "embedder_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "embedder = HuggingFaceBgeEmbeddings(\n",
    "    model_name=embedder_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# Recursive text splitter splits text into semantically meaningful chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "# This is where we will store the different chunks of text\n",
    "split_data = []\n",
    "\n",
    "for link in links:\n",
    "    good_2_go = True\n",
    "    try:\n",
    "        # Using newspaper3k to download and parse the article\n",
    "        article = Article(link)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "    except:\n",
    "        # There are certain articles that newspaper3k can't parse\n",
    "        # I catch those here and see if they are of any value (They usually aren't)\n",
    "        good_2_go = False\n",
    "        print(\"ERROR DOWNLOADING ARTICLE:\", link)\n",
    "    \n",
    "    # This metadata will be added to the beginning of each chunk\n",
    "    # Doing this decreases hallucinations in citations\n",
    "    meta_data = f\"Source \\n Title: {article.title} \\n Url: {link} \\\n",
    "        n Publish Date: {article.publish_date} \\n  Excerpt from source: \"\n",
    "\n",
    "    if good_2_go and not article.text is None:\n",
    "        # Splitting\n",
    "        candidate = text_splitter.create_documents([article.text])\n",
    "\n",
    "        temp_split_data = text_splitter.split_documents(candidate)\n",
    "\n",
    "        # Adding metadata to each chunk\n",
    "        for split in temp_split_data:\n",
    "            split.page_content = meta_data + split.page_content\n",
    "        \n",
    "        split_data += temp_split_data\n",
    "\n",
    "# vectorstore is the vector database using lightweight Chromadb\n",
    "vectorstore = Chroma.from_documents(documents=split_data, embedding=embedder)\n",
    "\n",
    "# Yet another part of langchain's abstractions\n",
    "# Used to parse the output of the model\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Lets us query the db to fill out the prompt template below\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": vectorstore.as_retriever(), \"question\": RunnablePassthrough()}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template and initializing chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt engineering is a constant process, especially with a smaller model\n",
    "template = \"\"\"\n",
    "You are a news expert who answers questions about news.  \n",
    "\n",
    "You must only use the most recent data from this context:\n",
    "{context}\n",
    "\n",
    "Do not rely on your historical records.\n",
    "\n",
    "Answer as concisely as possible, but make sure that your information\n",
    "lines up with the sources.  \n",
    "\n",
    "Your answer should be in the following format:\n",
    "    Your answer to the question here.\n",
    "\n",
    "    Sources: [article title, source link, publish date]\n",
    "\n",
    "Cite all Possible sources and put each on a new line.\n",
    "If you don't have the relevent information to answer the question or a source,\n",
    "tell the user so.  Err on the side of caution.\n",
    "\n",
    "If the question or topic is off topic and not about news at all, tell the user so.\n",
    "\n",
    "Here is the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# The final runnable in the chain\n",
    "chain = setup_and_retrieval | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up and running!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': [Document(page_content='Source \\n Title: EU asks Meta for more details on efforts to stop Israel-Hamas war misinformation \\n Url: https://www.cnn.com/2023/10/19/tech/eu-meta-tiktok-israel-content-disinformation/index.html \\n Publish Date: 2023-10-19 00:00:00 \\n  Excerpt from source: London CNN —\\n\\nThe European Union has told Meta it has a week to explain in greater detail how it is fighting the spread of illegal content and disinformation on its Facebook and Instagram platforms following the attacks across Israel by Hamas.\\n\\nThe European Commission, the bloc’s executive arm, said it had sent the formal request for information to Meta (META) Thursday.'), Document(page_content='Source \\n Title: EU asks Meta for more details on efforts to stop Israel-Hamas war misinformation \\n Url: https://www.cnn.com/2023/10/19/tech/eu-meta-tiktok-israel-content-disinformation/index.html \\n Publish Date: 2023-10-19 00:00:00 \\n  Excerpt from source: On Friday, Meta said its teams had been working “around the clock” since the attacks by Hamas on October 7 to monitor its platforms and outlined some of its actions against misinformation and content that violates its policies and standards.'), Document(page_content='Source \\n Title: EU asks Meta for more details on efforts to stop Israel-Hamas war misinformation \\n Url: https://www.cnn.com/2023/10/19/tech/eu-meta-tiktok-israel-content-disinformation/index.html \\n Publish Date: 2023-10-19 00:00:00 \\n  Excerpt from source: And on Sunday, TikTok announced that it had, among other measures, launched a command center to coordinate the work of its “safety professionals” around the world and improve the software it uses to automatically detect and remove graphic and violent content.'), Document(page_content='Source \\n Title: Fake placenames with anti-Israel messages flood Google Maps’ depiction of the Rafah border crossing between Gaza and Egypt \\n Url: https://www.cnn.com/2023/10/24/tech/anti-israel-messages-google-maps-rafah-border-crossing/index.html \\n Publish Date: 2023-10-24 00:00:00 \\n  Excerpt from source: Google, which also owns the map service Waze, said on Monday it was disabling its live traffic data in Israel and Gaza as Israeli forces prepare for a potential ground invasion of Gaza.\\n\\nThe company did not say if the action was at the request of the Israel Defense Forces. CNN reached out to the IDF for comment.\\n\\nGoogle took the same action at the beginning of Russia’s invasion of Ukraine last year after online researchers used live traffic data to track the movements of Russian troops.')], 'question': 'What is the most recent news in Isreal?'}\n",
      "\n",
      "The most recent news in Israel relates to the ongoing conflict with Hamas. The European Union has asked Meta, the parent company of Facebook and Instagram, for more details on its efforts to stop the spread of illegal content and disinformation related to the conflict on its platforms (Source: [ EU asks Meta for more details on efforts to stop Israel-Hamas war misinformation](https://www.cnn.com/2023/10/19/tech/eu-meta-tiktok-israel-content-disinformation/index.html), Publish Date: 2023-10-19). Meta has been working \"around the clock\" to monitor its platforms and remove content that violates its policies and standards (Source: [ EU asks Meta for more details on efforts to stop Israel-Hamas war misinformation](https://www.cnn.com/2023/10/19/tech/eu-meta-tiktok-israel-content-disinformation/index.html), Publish Date: 2023-10-19).\n",
      "\n",
      "Additionally, Google has disabled its live traffic data in Israel and Gaza as Israeli forces prepare for a potential ground invasion of Gaza (Source: [Fake placenames with anti-Israel messages flood Google Maps’ depiction of the Rafah border crossing between Gaza and Egypt](https://www.cnn.com/2023/10/24/tech/anti-israel-messages-google-maps-rafah-border-crossing/index.html), Publish Date: 2023-10-24).\n",
      "\n",
      "Sources:\n",
      "\n",
      "* EU asks Meta for more details on efforts to stop Israel-Hamas war misinformation: <https://www.cnn.com/2023/10/19/tech/eu-meta-tiktok-israel-content-disinformation/index.html>, Publish Date: 2023-10-19\n",
      "* Fake placenames with anti-Israel messages flood Google Maps’ depiction of the Rafah border crossing between Gaza and Egypt: <https://www.cnn.com/2023/10/24/tech/anti-israel-messages-google-maps-rafah-border-crossing/index.html>, Publish Date: 2023-10-24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question = \"What is the most recent news in Isreal?\"\n",
    "\n",
    "# I want to see what context the model is using to answer the question\n",
    "print(\"CONTEXT FETCHED:\")\n",
    "print(setup_and_retrieval.invoke(question))\n",
    "\n",
    "print(\"---------------\")\n",
    "\n",
    "print(\"\\nANSWER:\")\n",
    "print(chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "This notebook is more of a proof of concept that we can use LLMs to parse through news.  It's not meant to be perfect and it certainly isn't.\n",
    "\n",
    "The design could be improved in the following ways (no particular order):\n",
    "\n",
    " - Improving from a 7b model.  Probably the biggest barrier is that a 7b model's outputs can only be so good.  It often doesn't follow instuctions or just avoids outputting sometimes.  Perhaps this behavior would change with a better model, though I'm skeptical that I'd be able to run any larger model on my M1 8GB.\n",
    " - Fine tuning on custom dataset.  Might be possible on slightly better computer using some kind of PEFT technique.  I'd have to use gpt to get me some traning data, though.\n",
    " - Improve news collection pipeline.  It's important to get a variety of sources, and maybe the best way to do that is not just through arbirary RSS feeds.\n",
    " - LLM memory.  The ability to ask follow up questions would be nice, but I doubt this model's ability to handle very specific questions.\n",
    "  - Better prompt engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
